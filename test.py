"""comp5349_a2_500615485_testData.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1QS7of1hdgVzKvtokPKMI8CQzlhIYX5Gw
### Introduction
This notebook demonstrates a few useful methods for loading json file and for handling nested json objects. The example file is `test.json` in assignment 2.
"""

from pyspark.sql import SparkSession
spark = SparkSession \
    .builder \
    .appName("COMP5349 A2 Data Loading Example") \
    .getOrCreate()

"""### Load Json file as data frame"""

data = "s3://comp5349ranzhang/test.json"
init_df = spark.read.json(data)

# The original file will be loaded into a data frame with one row and two columns
init_df.show(1)

"""### Check the schema of a data frame
`printSchema` is a useful method to display the schema of a data frame
"""

init_df.printSchema()

"""### `select` and `explode`
The [`select`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.select.html) method is used to select one or more columns for the source dataframe. 
The [`explode`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.functions.explode.html) method is used to expand an array into multiple rows. The [`alias`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.Column.alias.html) method is used to specify a name for column storing the array element.
"""

from pyspark.sql.functions import explode
data_df= init_df.select((explode("data").alias('data')))

data_df.printSchema()

#total number of test contracts are 102
total_num = data_df.count()

#select the paragraphs named paragraph as new test_paragraph_df
paragraph_df = data_df.select((explode("data.paragraphs").alias("paragraph")))
paragraph_df.printSchema()

#select the qas&context part as new df
qas_context_df = paragraph_df.select("paragraph.context",(explode("paragraph.qas").alias("qas")))
qas_context_df.printSchema()


